{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB: 9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The expansion for CC,RB,IN,NN,JJ"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " CC: Coordinating conjunction\n",
    " RB: Adverb\n",
    " IN: Preposition or subordinating conjunction\n",
    " NN: Noun, singular or mass\n",
    " JJ: Adjective"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\1mscdsa39\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "tagsen=brown.tagged_sents()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagsen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PPSS'),\n",
       " ('was', 'BEDZ'),\n",
       " ('loaded', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('suds', 'NNS'),\n",
       " ('when', 'WRB'),\n",
       " ('I', 'PPSS'),\n",
       " ('ran', 'VBD'),\n",
       " ('away', 'RB'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PPSS'),\n",
       " (\"haven't\", 'HV*'),\n",
       " ('had', 'HVN'),\n",
       " ('a', 'AT'),\n",
       " ('chance', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('wash', 'VB'),\n",
       " ('it', 'PPO'),\n",
       " ('off', 'RP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagsen = brown.tagged_sents()\n",
    "total_sentences = len(tagsen)\n",
    "\n",
    "train_sents = tagsen[:50000]\n",
    "test_sents = tagsen[50000:]\n",
    "test_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tagged sentences: 57340\n",
      "Number of sentences in training set: 50000\n",
      "Number of sentences in testing set: 7340\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tagged sentences:\", total_sentences)\n",
    "print(\"Number of sentences in training set:\", len(train_sents))\n",
    "print(\"Number of sentences in testing set:\", len(test_sents))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "bigram_tagger = nltk.BigramTagger(brown.tagged_sents(), backoff=default_tagger)\n",
    "unigram_tagger = nltk.UnigramTagger(brown.tagged_sents(), backoff=bigram_tagger)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9228593574774061\n"
     ]
    }
   ],
   "source": [
    "test_sents = brown.tagged_sents()[50000:]\n",
    "print(\"Accuracy:\", unigram_tagger.evaluate(test_sents))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total words in the training set: 1039920\n",
      "Number of total words in the testing set: 121272\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "train_words = [word for sent in train_sents for word, tag in sent]\n",
    "num_train_words = len(train_words)\n",
    "\n",
    "test_words = [word for sent in test_sents for word, tag in sent]\n",
    "num_test_words = len(test_words)\n",
    "\n",
    "print(\"Number of total words in the training set:\", num_train_words)\n",
    "print(\"Number of total words in the testing set:\", num_test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Tagger Accuracy: 0.1091925588759153\n",
      "Unigram Tagger Accuracy: 0.9228593574774061\n",
      "Improvement from Default to Unigram Tagger: 0.8136667986014908\n",
      "Bigram Tagger Accuracy: 0.9472095784682367\n",
      "Improvement from Unigram to Bigram Tagger: 0.024350220990830618\n"
     ]
    }
   ],
   "source": [
    "#2 \n",
    "\n",
    "default_acc = default_tagger.evaluate(test_sents)\n",
    "print(\"Default Tagger Accuracy:\", default_acc)\n",
    "\n",
    "unigram_acc = unigram_tagger.evaluate(test_sents)\n",
    "print(\"Unigram Tagger Accuracy:\", unigram_acc)\n",
    "\n",
    "improvement1 = unigram_acc - default_acc\n",
    "print(\"Improvement from Default to Unigram Tagger:\", improvement1)\n",
    "\n",
    "bigram_acc = bigram_tagger.evaluate(test_sents)\n",
    "print(\"Bigram Tagger Accuracy:\", bigram_acc)\n",
    "\n",
    "improvement2 = bigram_acc - unigram_acc\n",
    "print(\"Improvement from Unigram to Bigram Tagger:\", improvement2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')] \n",
      "\n",
      "\n",
      "[('``', '``'), ('I', 'PPSS'), ('told', 'VBD'), ('him', 'PPO'), ('who', 'WPS'), ('I', 'PPSS'), ('was', 'BEDZ'), ('and', 'CC'), ('he', 'PPS'), ('was', 'BEDZ'), ('quite', 'QL'), ('cold', 'JJ'), ('.', '.')] \n",
      "\n",
      "\n",
      "('cold', 'JJ') \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "print(train_sents[0],\"\\n\\n\")\n",
    "print(train_sents [1277],\"\\n\\n\")\n",
    "print(train_sents [1277][11],\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.'), ('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD')] \n",
      "\n",
      "\n",
      "('election', 'NN') \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "train_sents_flat=[(word,tag) for sent in train_sents for (word,tag) in sent]\n",
    "print(train_sents_flat[:40],\"\\n\\n\")\n",
    "print(train_sents_flat[13],\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'JJ': 110, 'NN': 8, 'RB': 2})\n"
     ]
    }
   ],
   "source": [
    "#5)\n",
    "#a)\n",
    "\n",
    "from collections import defaultdict\n",
    "tag_freq = defaultdict(int)\n",
    "for sent in train_sents:\n",
    "    for word, tag in sent:\n",
    "        if word == 'cold':\n",
    "            tag_freq[tag] += 1\n",
    "print(tag_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'JJ': 148, 'NN': 12, 'RB': 2})\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "\n",
    "\n",
    "for sent in train_sents:\n",
    "    for i in range(1, len(sent)):\n",
    "        if sent[i][0] == 'cold' and sent[i-1][1] == 'AT':\n",
    "            tag_freq[sent[i][1]] += 1\n",
    "print(tag_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'JJ': 152, 'NN': 14, 'RB': 2})\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "\n",
    "\n",
    "for sent in train_sents:\n",
    "    for i in range(1, len(sent)):\n",
    "        if sent[i][0] == 'cold' and sent[i-1][1] == 'JJ':\n",
    "            tag_freq[sent[i][1]] += 1\n",
    "print(tag_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'JJ': 152, 'NN': 14, 'RB': 2, ('QL', 'JJ'): 7, ('AT', 'JJ'): 38, ('IN', 'JJ'): 14, ('CS', 'JJ'): 1, ('JJ', 'NN'): 2, ('``', 'JJ'): 2, ('CC', 'JJ'): 8, ('BEZ', 'JJ'): 1, ('DOZ', 'JJ'): 1, ('AT', 'NN'): 4, (',', 'NN'): 1, ('DT', 'JJ'): 3, ('NN', 'JJ'): 2, (',', 'JJ'): 3, ('VBN', 'JJ'): 2, ('VBD', 'JJ'): 2, ('RB', 'JJ'): 1, ('PPSS', 'JJ'): 1, ('BE', 'JJ'): 1, ('VB', 'JJ'): 1, ('DT', 'NN'): 1, ('JJ', 'JJ'): 4, ('VBZ', 'JJ'): 1, ('PP$', 'JJ'): 3, ('NP$', 'JJ'): 1, ('BEDZ', 'JJ'): 7, ('RP', 'RB'): 2, ('BEDZ*', 'JJ'): 1, ('--', 'JJ'): 1, ('RP', 'JJ'): 1, ('DTI', 'JJ'): 1, ('WRB', 'JJ'): 1, ('BED', 'JJ'): 1})\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "\n",
    "\n",
    "for sent in train_sents:\n",
    "    for i in range(1, len(sent)):\n",
    "        if sent[i][0] == 'cold':\n",
    "            tag_freq[sent[i-1][1], sent[i][1]] += 1\n",
    "print(tag_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "bt=nltk.BigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PPSS'), ('was', 'BEDZ'), ('very', 'QL'), ('cold', 'JJ')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "a=word_tokenize(\"I was very cold\")\n",
    "bt.tag(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PPSS'), ('had', 'HVD'), ('a', 'AT'), ('cold', 'JJ')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b)\n",
    "b=word_tokenize(\"I had a cold\")\n",
    "bt.tag(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PPSS'), ('had', 'HVD'), ('a', 'AT'), ('severe', 'JJ'), ('cold', 'JJ')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)\n",
    "c=word_tokenize(\"I had a severe cold\")\n",
    "bt.tag(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('January', None),\n",
       " ('was', None),\n",
       " ('a', None),\n",
       " ('cold', None),\n",
       " ('month', None)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d)\n",
    "d=word_tokenize(\"January was a cold month\")\n",
    "bt.tag(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have already run the bigram tagger on the four sentences in the previous step and provided the output for each sentence. \n",
    "Here is a summary of the results:\n",
    "\n",
    "(a) Output: [('I', 'PPSS'), ('was', 'BEDZ'), ('very', 'QL'), ('cold', 'JJ')]\n",
    "\n",
    "(b) Output: [('I', 'PPSS'), ('had', 'HVD'), ('a', 'AT'), ('cold', 'JJ')]\n",
    "\n",
    "(c) Output: [('I', 'PPSS'), ('had', 'HVD'), ('a', 'AT'), ('severe', 'JJ'), ('cold', 'JJ')]\n",
    "\n",
    "(d) Output: [('January', None), ('was', None), ('a', None), ('cold', None), ('month', None)]\n",
    "\n",
    "As predicted, the bigram tagger was able to tag the first three sentences fairly accurately, \n",
    "but it failed to tag any of the words in the fourth sentence due to the lack of training data for those particular \n",
    "word combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PPSS'), ('failed', 'VBD'), ('to', 'TO'), ('do', 'DO'), ('so', 'RB')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8)\n",
    "#a)\n",
    "a=word_tokenize(\"I failed to do so\")\n",
    "bt.tag(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PPSS'),\n",
       " ('was', 'BEDZ'),\n",
       " ('happy', 'JJ'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('was', 'BEDZ'),\n",
       " ('my', 'PP$'),\n",
       " ('enemy', 'NN')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b)\n",
    "b=word_tokenize(\"I was happy, but so was my enemy\")\n",
    "bt.tag(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('So', 'RB'),\n",
       " (',', ','),\n",
       " ('how', 'WRB'),\n",
       " ('was', 'BEDZ'),\n",
       " ('the', 'AT'),\n",
       " ('exam', None),\n",
       " ('?', None)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)\n",
    "c=word_tokenize(\"So, how was the exam?\")\n",
    "bt.tag(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('students', 'NNS'),\n",
       " ('came', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('easly', None),\n",
       " ('so', None),\n",
       " ('they', None),\n",
       " ('can', None),\n",
       " ('get', None),\n",
       " ('good', None),\n",
       " ('seats', None)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d)\n",
    "d=word_tokenize(\"The students came in easly so they can get good seats\")\n",
    "bt.tag(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PPS'),\n",
       " ('failed', 'VBD'),\n",
       " ('the', 'AT'),\n",
       " ('exam', None),\n",
       " (',', None),\n",
       " ('so', None),\n",
       " ('she', None),\n",
       " ('must', None),\n",
       " ('take', None),\n",
       " ('it', None),\n",
       " ('again', None)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e)\n",
    "e=word_tokenize(\"She failed the exam, so she must take it again\")\n",
    "bt.tag(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('That', 'DT'), ('was', 'BEDZ'), ('so', 'QL'), ('incredible', 'JJ')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f)\n",
    "f=word_tokenize(\"That was so incredible\")\n",
    "bt.tag(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wow', None), (',', None), ('so', None), ('incredible', None)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#g)\n",
    "g=word_tokenize(\"Wow, so incredible\")\n",
    "bt.tag(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I can examine the tagger's performance on the sentences and explain how it determined the POS tag of the word 'so'.\n",
    "\n",
    "The tagger correctly identified the POS tag of 'so' in sentences (a), (c), (d), and (e), while incorrectly tagging 'so' as an adverb in sentences (b), (f), and (g). In sentences where the tagger was correct, it determined the POS tag by considering the context in which 'so' appears. However, in sentences where it was incorrect, the tagger likely misclassified 'so' based on its position in the sentence or the presence of other adverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The bigram tagger has strengths in considering the previous word's POS tag and handling unknown words. However, it has limitations in not considering other contextual information and being affected by data sparsity."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "UMESH C- 225229144"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
